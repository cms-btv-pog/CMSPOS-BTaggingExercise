{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "\n",
    "\n",
    "## Part I - creating a useful data format\n",
    "\n",
    "Like in the previous exercise you will start creating a `pandas.DataFrame` with the necessary information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ROOT\n",
    "import rootpy #hands down, a better version of PyROOT\n",
    "import rootpy.plotting as plt\n",
    "import pprint\n",
    "from DataFormats.FWLite import Events, Handle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "ROOT.gStyle.SetOptStat(0)\n",
    "ROOT.gStyle.SetOptTitle(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to import sevral libraries, including scikit-lean, one of the machine learning python libraries and matplotlib, one of python's plotting libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as pyplt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous exercise we will have to read the input `MINIAOD` files and convert the information we want into a `pandas.DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "files = [\n",
    "    #QCD\n",
    "    '/store/mc/RunIISummer16MiniAODv3/QCD_HT100to200_TuneCUETP8M1_13TeV-madgraphMLM-pythia8/MINIAODSIM/PUMoriond17_94X_mcRun2_asymptotic_v3-v1/90000/2C4EC498-DA21-E911-BDF4-001E67248476.root',\n",
    "    #'/store/relval/CMSSW_9_2_2/RelValQCD_FlatPt_15_3000HS_13/MINIAODSIM/PU25ns_92X_upgrade2017_realistic_v1-v1/10000/14008288-C84D-E711-9EFD-0025905B85BC.root',\n",
    "    #'/store/relval/CMSSW_9_2_2/RelValQCD_FlatPt_15_3000HS_13/MINIAODSIM/PU25ns_92X_upgrade2017_realistic_v1-v1/10000/30858183-C84D-E711-AB11-0CC47A7C3434.root',\n",
    "    #TTbar\n",
    "    '/store/mc/RunIISummer16MiniAODv3/TT_TuneCUETP8M2T4_13TeV-powheg-pythia8/MINIAODSIM/PUMoriond17_94X_mcRun2_asymptotic_v3-v1/00000/0A8930BA-88BE-E811-8BDD-20CF3027A582.root',\n",
    "    #'/store/relval/CMSSW_9_2_2/RelValTTbar_13/MINIAODSIM/PU25ns_92X_upgrade2017_realistic_v1-v1/10000/8E7EE25F-294E-E711-A5CC-0025905B8610.root',\n",
    "    #'/store/relval/CMSSW_9_2_2/RelValTTbar_13/MINIAODSIM/PU25ns_92X_upgrade2017_realistic_v1-v1/10000/44D6F368-294E-E711-958E-0025905A612C.root',\n",
    "]\n",
    "events = Events(['root://xrootd-cms.infn.it/%s' % i for i in files])\n",
    "handle = Handle('vector<pat::Jet>')\n",
    "taggers = [\n",
    "    ('JP', 'pfJetProbabilityBJetTags'),\n",
    "    ('JPB', 'pfJetBProbabilityBJetTags'),\n",
    "    ('SoftMu', 'softPFMuonBJetTags'),\n",
    "    ('SoftEl', 'softPFElectronBJetTags'),\n",
    "    ('CSV_IVF', 'pfCombinedInclusiveSecondaryVertexV2BJetTags'),\n",
    "    ('CSV_AVR', 'pfCombinedSecondaryVertexV2BJetTags'),\n",
    "    ('CvsL', 'pfCombinedCvsLJetTags'),\n",
    "    ('CvsB', 'pfCombinedCvsBJetTags'),\n",
    "    ('cMVA', 'pfCombinedMVAV2BJetTags'), #FOR REFERENCE ONLY\n",
    "]\n",
    "for event in events:\n",
    "    event.getByLabel('slimmedJets', handle)\n",
    "    jets = handle.product()\n",
    "    for jet in jets:\n",
    "        if jet.pt() < 20 or abs(jet.eta()) > 2.4: continue #basic selection\n",
    "        #A more verbose, but more consistent version with dictionaries exists\n",
    "        entry = [\n",
    "            jet.pt(),\n",
    "            jet.eta(),\n",
    "            abs(jet.hadronFlavour()), #5 - b-jet, 4 - c-jet, 0 - light\n",
    "        ]\n",
    "        entry.extend([jet.bDiscriminator(i) for _, i in taggers])\n",
    "        data.append(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert the data and look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(\n",
    "    data, \n",
    "    columns=(['pt', 'eta', 'flavour'] + [i for i, _ in taggers])\n",
    ")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Always sanitize your input__\n",
    "\n",
    "![img](img/xkcd.png)\n",
    "\n",
    "Let's check if there are columns with `inf`s or `NaN`s. We are sure about soft electron/muons, but what about the rest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for column in data.columns:\n",
    "    if np.isinf(data[column]).any():\n",
    "        print column, 'contains infs'\n",
    "    if np.isnan(data[column]).any():\n",
    "        print column, 'contains nans'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check yourself what are the ranged of the features with infinities, but setting them to 0 works for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.loc[np.isinf(data.SoftEl), 'SoftEl'] = 0\n",
    "data.loc[np.isinf(data.SoftMu), 'SoftMu'] = 0\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now have to set the true labels for the training/testing of our discriminator. We will create two sets of labels:\n",
    "  - __Binary labels:__ simply define if the jet is a b-jet or not\n",
    "  - __multiclass labels:__ define three possible options, light, charm and b. It is the same information we have in the flavour column, but encoded differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['binary_target'] = 0\n",
    "data.loc[(data.flavour == 5), 'binary_target'] = 1\n",
    "\n",
    "data['isL'] = (data.flavour == 0)\n",
    "data['isB'] = (data.flavour == 5)\n",
    "data['isC'] = (data.flavour == 4)\n",
    "data['clf_binary'] = 0\n",
    "data['clf_multiclass'] = 0\n",
    "data['clf_multiclass_C'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in every machine learning exercise, we need to split our data into two samples, a training and a testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define our models. We will train two different BDTs, one trained on binary labels, one with multiclass labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [] #FIXME!\n",
    "clf_binary = GradientBoostingClassifier(\n",
    "    learning_rate=0.01, n_estimators=1000, \n",
    "    subsample=0.8, random_state=13,\n",
    "    min_samples_leaf=int(0.01*len(train)),\n",
    "    max_depth=5,\n",
    "    verbose=1,\n",
    ")\n",
    "clf_multiclass = OneVsRestClassifier(sklearn.base.clone(clf_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training, takes a while\n",
    "clf_multiclass.fit(train[features], train[['isL', 'isC', 'isB']].as_matrix())\n",
    "clf_binary.fit(train[features], train.binary_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now store the output of the taggers in the columns we created before. Do not mind the warning coming from the command. \n",
    "\n",
    "You can see that the binary classifier outputs a N time 2 matrix corresponding to $p(non-b\\, |\\, jet)$, $p(b\\, |\\, jet)$, while the multiclass has three outputs $p(light\\, |\\, jet)$, $p(charm\\, |\\, jet)$, $p(b\\, |\\, jet)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test['clf_binary'] = clf_binary.predict_proba(test[features])[:,1]\n",
    "test['clf_multiclass'] = clf_multiclass.predict_proba(test[features])[:,2]\n",
    "test['clf_multiclass_C'] = clf_multiclass.predict_proba(test[features])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now print the ROC curves as in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = pyplt.figure(figsize=(15, 15), dpi= 80, facecolor='w', edgecolor='k')\n",
    "for algo, color in zip([\n",
    "    'cMVA', \n",
    "    'clf_binary', \n",
    "    'clf_multiclass',\n",
    "    ], 'rgb'):    \n",
    "    for bkg, style in zip([4, 0], ['-', '--']):\n",
    "        mask = (test.flavour != bkg)\n",
    "        jets = test[mask]\n",
    "        fakes_positive_rate, true_positive_rate, _ = roc_curve(jets.isB, jets[algo])\n",
    "        pyplt.plot(true_positive_rate, fakes_positive_rate, '%s%s' % (color, style))\n",
    "\n",
    "import matplotlib.lines as mlines\n",
    "pyplt.legend(\n",
    "    loc='best',\n",
    "    handles=[\n",
    "        mlines.Line2D([],[], color='red', ls='-', label='cMVAv2'),\n",
    "        mlines.Line2D([],[], color='green', ls='-', label='clf_binary'),\n",
    "        mlines.Line2D([],[], color='blue', ls='-', label='clf_multiclass'),\n",
    "        mlines.Line2D([],[], color='k', ls='-', label='b vs. light'),\n",
    "        mlines.Line2D([],[], color='k', ls='--', label='b vs. charm'),        \n",
    "        ])\n",
    "        \n",
    "pyplt.xlabel('efficiency')\n",
    "pyplt.ylabel('fake rate')\n",
    "pyplt.grid(True)\n",
    "pyplt.yscale('log', nonposy='clip')\n",
    "pyplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Can you make the charm-vs-light and charm-vs-b plots for the discriminators considered?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
